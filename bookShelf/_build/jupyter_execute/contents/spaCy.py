#!/usr/bin/env python
# coding: utf-8

# # GINZAとは
# 
# 「GINZA」とは、リクルートと国立国語研究所の共同研究によって2019年4月に公開されたPython向け日本語自然言語処理ライブラリです。
# 
# 
# これまでの自然言語処理ライブラリは独立した機能の物が多く、例えば[「MeCab」](http://mecab.sourceforge.net/)や[「Janome」](https://mocobeta.github.io/janome/)、[「Juman」](http://nlp.ist.i.kyoto-u.ac.jp/index.php?%E6%97%A5%E6%9C%AC%E8%AA%9E%E5%BD%A2%E6%85%8B%E7%B4%A0%E8%A7%A3%E6%9E%90%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0JUMAN)等は形態素解析、[「CaboCha」](http://code.google.com/p/cabocha/)や[「KNP」](http://nlp.ist.i.kyoto-u.ac.jp/index.php?%E6%97%A5%E6%9C%AC%E8%AA%9E%E6%A7%8B%E6%96%87%E8%A7%A3%E6%9E%90%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0KNP)等は係り受け解析を担うなど、応用を目指すにはこれらを組み合わせる専門知識とエンジニアリングが必要でした。
# 
# そこで形態素解析、係り受け解析などを標準で扱えるライブラリとしてGINZAが登場しました。
# 
# ---
# 
# ## GINZAの概要と特徴
# 
# >「GiNZA」は、最先端の機械学習技術を取り入れた自然言語処理ライブラリ「spaCy」をフレームワークとして利用しており、また、オープンソース形態素解析器「SudachiPy」を内部に組み込み、トークン化処理に利用している。「GiNZA日本語UDモデル」にはMegagon Labsと国立国語研究所の共同研究成果が組み込まれています
# 
# またGINZAの特徴は以下の通りです。
# 
# >1.高度な自然言語処理をワンステップで導入完了
# >これまで、高度な自然言語処理を行うためには複雑な導入作業が必要でしたが、「GiNZA」はワンステップでモジュールとモデルファイルの導入を完了できます。これにより、エンジニアは即座に解析が可能です。
# > 
# >2.高速・高精度な解析処理と依存構造解析レベルの国際化に対応
# >産業用途で自然言語処理技術を活用するには、一定の処理速度を保ちながら解析精度を高めるためにチューニングを行うことが一般的です。「GiNZA」は、「spaCy」が提供する高速・高精度な依存構造解析器を使用して、産業用途に耐える性能を備えた高度な自然言語処理機能をライブラリとして提供します。同時に、「spaCy」の国際化機能により、複数の欧米言語と日本語の言語リソースを切り替えて使用することが可能となり、エンジニアは複数言語の解析を単一のライブラリで行うことができます。
# > 
# >3.国立国語研究所との共同研究成果の学習モデルを提供
# 自然言語処理系の学会を中心に、人類が用いる多様な言語を、一貫した構文構造・品詞体系で解析可能にする>「Universal Dependencies」の取組みが、2014年から全世界で始まっています。日本においても当初からUDの日本語への適用に関する研究と日本語版UDコーパス（データ）構築が同時に進められてきました。Megagon Labsは、国立国語研究所と共同で、日本語版UDに基づいた高精度な依存構造解析技術の研究を行い、その成果である学習済みモデルを「GiNZA日本語UDモデル」に組み込みました。
# 「GiNZA日本語UDモデル」は、国立国語研究所が長年の研究を通じて蓄積してきた大規模かつ高品質なテキストコーパスに加えて、日本語Wikipediaテキストも同時に用いて機械学習に適用することで、幅広い分野に適応可能なモデルを構築しています。
# 
# つまりはこれまで自然言語処理を始めるには機能独立したライブラリそれぞれを準備する必要がありましたが、「GINZA」を準備するだけで始める準備が終わることになります。
# 
# 引用元[リクルートのAI研究機関、国立国語研究所との共同研究成果を用いた日本語の自然言語処理ライブラリ「GiNZA」を公開](https://www.recruit.co.jp/newsroom/2019/0402_18331.html)
# 

# ### spaCyとは
# 「GINZA」が使用している「spaCy」は、Pythonで高度な自然言語処理(NLP)を行うためのフリーのオープンソースライブラリです。最新の研究を元に各機能は作られており、産業製品用途に耐えうるように特別に設計されています。この点が教育や研究用途のNLTKやCoreNLPのようなライブラリとは異なります。しかし、spaCyができることは数多く、情報抽出や自然言語理解システムの構築、またはDNNの前処理などに役立ちます。
# 
# ---
# 
# ### spaCyの機能
# spaCyの機能についてまとめた表を示します。
# 
# 処理 | 説明
# --- | ---
# トークン化 | テキストを単語や句読点などに分割します。
# 品詞（POS: Part-of-speech）タグ付け | 動詞や名詞などのトークンに単語タイプを割り当てます。
# 依存関係の解析 | 主語や目的語のように、個々のトークン間の関係を記述する構文依存性ラベルを割り当てます。
# 語の見出し語化(Lemmatization) | 単語の基本形を割り当てる。例えば、"was "の見出しは "be "であり、"rats "の見出しは "rat "である。
# 文境界検出 (SBD:Sentence Boundary Detection) | 個々の文を見つけてセグメント化します。
# 固有表現抽出(NER:Named Entity Recognition ) | 人、会社、場所など、名前のついた「実世界」のオブジェクトをラベリングします。
# エンティティリンク (EL:Entity Linking)  | テキストのエンティティを、知識ベース内の一意の識別子と区別します。
# 類似性(Similarity) | 単語、テキストスパン、ドキュメントを比較し、それらが互いにどの程度似ているかを比較します。
# テキスト分類 | 文書全体または文書の一部にカテゴリやラベルを割り当てます。
# ルールベースのマッチング | 正規表現に似た、テキストと言語的注釈に基づいて、トークンのシーケンスを見つけます。
# トレーニング | 統計モデルの予測を更新したり、改善したりすること。
# シリアライゼーション | オブジェクトをファイルやバイト文字列に保存します。
# 
# 上記の処理機能の一部は独立して使用可能ですが、その他は言語アノテーションを予測するための統計モデルをロードする必要があります。統計モデルには、通常、以下のコンポーネントが含まれています。
# 
# コンポーネント　|　説明
# --- | ---
# 品詞タグ付けのためのバイナリ重み | 依存性パーサ、および文脈でのアノテーションを予測するための名前付きエンティティ認識器に使用
# 語彙エントリ | 単語とその形やスペルなどの文脈に依存しない属性。
# データファイル | 見出し語化ルールやルックアップテーブルなど。
# 単語ベクトル　 | 単語の多次元的な意味表現で、単語同士の類似度を判断する。
# コンフィグレーション | 言語や処理パイプラインの設定のような設定オプション
# 
# 以降はコードと共に機能について見ていきます。
# 
# 
# ## Ref
# - [自然言語処理ライブラリ一覧](http://www.phontron.com/nlptools.php?lang=ja)
# 
# - [GiNZA - Japanese NLP Library](https://megagonlabs.github.io/ginza/)
# 
# - [日本語ライブラリGINZAのススメ](https://qiita.com/poyo46/items/7a4965455a8a2b2d2971)
# 
# - [自然言語処理ライブラリGiNZAをインストールして簡単に動かすまでの手順](https://www.virment.com/how-to-install-ginza-and-use/)
# 
# - [spaCyとGiNZAを用いた言語処理](https://www.koi.mashykom.com/spacy_ginza.html)
# 
# - [正規表現・自然言語処理](https://petitviolet.hatenablog.com/entry/20120523/1337760714)
# 
# 
# - [spacy](https://spacy.io/usage/spacy-101)
# - [spacy翻訳](https://note.com/npaka/n/nc608b9392300?magazine_key=m9a7d32c95ad9)
# 
# 

# In[1]:


get_ipython().system('pip install ginza')


# In[2]:


from ginza import *
import spacy

nlp = spacy.load("ja_ginza")  # GiNZAモデルの読み込み
doc = nlp('銀座でランチをご一緒しましょう。')

for token in doc:
    print(token.text, token.pos_, token.dep_)


# In[3]:


get_ipython().system('pip install ginza')


# In[ ]:




