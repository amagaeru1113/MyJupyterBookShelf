
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>GINZAとspaCy &#8212; Iron Ball Run</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.2d2078699c18a0efb88233928e1cf6ed.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.be0a4a0c39cd630af62a2fcf693f3f06.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="記事翻訳" href="translation/trans.html" />
    <link rel="prev" title="What is GINZA?" href="IntroToGINZA.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/ironball.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Iron Ball Run</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="IntroAndContentsInJB/intro.html">
   Welcome to Iron Ball Run
  </a>
 </li>
</ul>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="IntroAndContentsInJB/content.html">
   Content in Jupyter Book
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="reference internal" href="IntroToGINZA.html">
   What is GINZA?
  </a>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     GINZAとspaCy
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="translation/trans.html">
   記事翻訳
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="software_testing/intro.html">
   ソフトウェアテスト技法について
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/contents/spaCy.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/contents/spaCy.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ginza">
   GINZAとは
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   GINZAの概要と特徴
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spacy">
   spaCyとは
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   spaCyの機能
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ref">
   Ref
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   言語アノテーション
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#token">
   Token化
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id4">
   品詞タグと依存関係
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id5">
   固有表現
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id6">
   単語ベクトルと類似度
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   パイプライン
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#vocab-hashe-lexeme">
   語彙(Vocab)、ハッシュ(hashe)、見出し(lexeme)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id8">
   ナレッジベース
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id9">
   候補生成
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id10">
   シリアライズ
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id11">
   訓練
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id12">
   言語データ
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id13">
   アーキテクチャ
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="ginzaspacy">
<h1>GINZAとspaCy<a class="headerlink" href="#ginzaspacy" title="Permalink to this headline">¶</a></h1>
<div class="section" id="ginza">
<h2>GINZAとは<a class="headerlink" href="#ginza" title="Permalink to this headline">¶</a></h2>
<p>「GINZA」とは、リクルートと国立国語研究所の共同研究によって2019年4月に公開されたPython向け日本語自然言語処理ライブラリです。</p>
<p>これまでの自然言語処理ライブラリは独立した機能の物が多く、例えば<a class="reference external" href="http://mecab.sourceforge.net/">「MeCab」</a>や<a class="reference external" href="https://mocobeta.github.io/janome/">「Janome」</a>、<a class="reference external" href="http://nlp.ist.i.kyoto-u.ac.jp/index.php?%E6%97%A5%E6%9C%AC%E8%AA%9E%E5%BD%A2%E6%85%8B%E7%B4%A0%E8%A7%A3%E6%9E%90%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0JUMAN">「Juman」</a>等は形態素解析、<a class="reference external" href="http://code.google.com/p/cabocha/">「CaboCha」</a>や<a class="reference external" href="http://nlp.ist.i.kyoto-u.ac.jp/index.php?%E6%97%A5%E6%9C%AC%E8%AA%9E%E6%A7%8B%E6%96%87%E8%A7%A3%E6%9E%90%E3%82%B7%E3%82%B9%E3%83%86%E3%83%A0KNP">「KNP」</a>等は係り受け解析を担うなど、応用を目指すにはこれらを組み合わせる専門知識とエンジニアリングが必要でした。</p>
<p>そこで形態素解析、係り受け解析などを標準で扱えるライブラリとしてGINZAが登場しました。</p>
</div>
<div class="section" id="id1">
<h2>GINZAの概要と特徴<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div><p>「GiNZA」は、最先端の機械学習技術を取り入れた自然言語処理ライブラリ「spaCy」をフレームワークとして利用しており、また、オープンソース形態素解析器「SudachiPy」を内部に組み込み、トークン化処理に利用している。「GiNZA日本語UDモデル」にはMegagon Labsと国立国語研究所の共同研究成果が組み込まれています</p>
</div></blockquote>
<p>またGINZAの特徴は以下の通りです。</p>
<blockquote>
<div><p>1.高度な自然言語処理をワンステップで導入完了
これまで、高度な自然言語処理を行うためには複雑な導入作業が必要でしたが、「GiNZA」はワンステップでモジュールとモデルファイルの導入を完了できます。これにより、エンジニアは即座に解析が可能です。</p>
<p>2.高速・高精度な解析処理と依存構造解析レベルの国際化に対応
産業用途で自然言語処理技術を活用するには、一定の処理速度を保ちながら解析精度を高めるためにチューニングを行うことが一般的です。「GiNZA」は、「spaCy」が提供する高速・高精度な依存構造解析器を使用して、産業用途に耐える性能を備えた高度な自然言語処理機能をライブラリとして提供します。同時に、「spaCy」の国際化機能により、複数の欧米言語と日本語の言語リソースを切り替えて使用することが可能となり、エンジニアは複数言語の解析を単一のライブラリで行うことができます。</p>
<p>3.国立国語研究所との共同研究成果の学習モデルを提供
自然言語処理系の学会を中心に、人類が用いる多様な言語を、一貫した構文構造・品詞体系で解析可能にする&gt;「Universal Dependencies」の取組みが、2014年から全世界で始まっています。日本においても当初からUDの日本語への適用に関する研究と日本語版UDコーパス（データ）構築が同時に進められてきました。Megagon Labsは、国立国語研究所と共同で、日本語版UDに基づいた高精度な依存構造解析技術の研究を行い、その成果である学習済みモデルを「GiNZA日本語UDモデル」に組み込みました。
「GiNZA日本語UDモデル」は、国立国語研究所が長年の研究を通じて蓄積してきた大規模かつ高品質なテキストコーパスに加えて、日本語Wikipediaテキストも同時に用いて機械学習に適用することで、幅広い分野に適応可能なモデルを構築しています。</p>
</div></blockquote>
<p>つまりはこれまで自然言語処理を始めるには機能独立したライブラリそれぞれを準備する必要がありましたが、「GINZA」を準備するだけで始める準備が終わることになります。</p>
<p>引用元<a class="reference external" href="https://www.recruit.co.jp/newsroom/2019/0402_18331.html">リクルートのAI研究機関、国立国語研究所との共同研究成果を用いた日本語の自然言語処理ライブラリ「GiNZA」を公開</a></p>
</div>
<div class="section" id="spacy">
<h2>spaCyとは<a class="headerlink" href="#spacy" title="Permalink to this headline">¶</a></h2>
<p>「GINZA」が使用している「spaCy」は、Pythonで高度な自然言語処理(NLP)を行うためのフリーのオープンソースライブラリです。最新の研究を元に各機能は作られており、産業製品用途に耐えうるように特別に設計されています。この点が教育や研究用途のNLTKやCoreNLPのようなライブラリとは異なります。しかし、spaCyができることは数多く、情報抽出や自然言語理解システムの構築、またはDNNの前処理などに役立ちます。</p>
</div>
<div class="section" id="id2">
<h2>spaCyの機能<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p>spaCyの機能についてまとめた表を示します。</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>処理</p></th>
<th class="head"><p>説明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>トークン化</p></td>
<td><p>テキストを単語や句読点などに分割します。</p></td>
</tr>
<tr class="row-odd"><td><p>品詞（POS: Part-of-speech）タグ付け</p></td>
<td><p>動詞や名詞などのトークンに単語タイプを割り当てます。</p></td>
</tr>
<tr class="row-even"><td><p>依存関係の解析</p></td>
<td><p>主語や目的語のように、個々のトークン間の関係を記述する構文依存性ラベルを割り当てます。</p></td>
</tr>
<tr class="row-odd"><td><p>語の見出し語化(Lemmatization)</p></td>
<td><p>単語の基本形を割り当てる。例えば、”was “の見出しは “be “であり、”rats “の見出しは “rat “である。</p></td>
</tr>
<tr class="row-even"><td><p>文境界検出 (SBD:Sentence Boundary Detection)</p></td>
<td><p>個々の文を見つけてセグメント化します。</p></td>
</tr>
<tr class="row-odd"><td><p>固有表現抽出(NER:Named Entity Recognition )</p></td>
<td><p>人、会社、場所など、名前のついた「実世界」のオブジェクトをラベリングします。</p></td>
</tr>
<tr class="row-even"><td><p>エンティティリンク (EL:Entity Linking)</p></td>
<td><p>テキストのエンティティを、知識ベース内の一意の識別子と区別します。</p></td>
</tr>
<tr class="row-odd"><td><p>類似性(Similarity)</p></td>
<td><p>単語、テキストスパン、ドキュメントを比較し、それらが互いにどの程度似ているかを比較します。</p></td>
</tr>
<tr class="row-even"><td><p>テキスト分類</p></td>
<td><p>文書全体または文書の一部にカテゴリやラベルを割り当てます。</p></td>
</tr>
<tr class="row-odd"><td><p>ルールベースのマッチング</p></td>
<td><p>正規表現に似た、テキストと言語的注釈に基づいて、トークンのシーケンスを見つけます。</p></td>
</tr>
<tr class="row-even"><td><p>トレーニング</p></td>
<td><p>統計モデルの予測を更新したり、改善したりすること。</p></td>
</tr>
<tr class="row-odd"><td><p>シリアライゼーション</p></td>
<td><p>オブジェクトをファイルやバイト文字列に保存します。</p></td>
</tr>
</tbody>
</table>
<p>上記の処理機能の一部は独立して使用可能ですが、その他は言語アノテーションを予測するための統計モデルをロードする必要があります。統計モデルには、通常、以下のコンポーネントが含まれています。</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>コンポーネント</p></th>
<th class="head"><p>説明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>品詞タグ付けのためのバイナリ重み</p></td>
<td><p>依存性パーサ、および文脈でのアノテーションを予測するための名前付きエンティティ認識器に使用</p></td>
</tr>
<tr class="row-odd"><td><p>語彙エントリ</p></td>
<td><p>単語とその形やスペルなどの文脈に依存しない属性。</p></td>
</tr>
<tr class="row-even"><td><p>データファイル</p></td>
<td><p>見出し語化ルールやルックアップテーブルなど。</p></td>
</tr>
<tr class="row-odd"><td><p>単語ベクトル</p></td>
<td><p>単語の多次元的な意味表現で、単語同士の類似度を判断する。</p></td>
</tr>
<tr class="row-even"><td><p>コンフィグレーション</p></td>
<td><p>言語や処理パイプラインの設定のような設定オプション</p></td>
</tr>
</tbody>
</table>
<p>以降はコードと共に機能について見ていきます。</p>
</div>
<div class="section" id="ref">
<h2>Ref<a class="headerlink" href="#ref" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="http://www.phontron.com/nlptools.php?lang=ja">自然言語処理ライブラリ一覧</a></p></li>
<li><p><a class="reference external" href="https://megagonlabs.github.io/ginza/">GiNZA - Japanese NLP Library</a></p></li>
<li><p><a class="reference external" href="https://qiita.com/poyo46/items/7a4965455a8a2b2d2971">日本語ライブラリGINZAのススメ</a></p></li>
<li><p><a class="reference external" href="https://www.virment.com/how-to-install-ginza-and-use/">自然言語処理ライブラリGiNZAをインストールして簡単に動かすまでの手順</a></p></li>
<li><p><a class="reference external" href="https://www.koi.mashykom.com/spacy_ginza.html">spaCyとGiNZAを用いた言語処理</a></p></li>
<li><p><a class="reference external" href="https://petitviolet.hatenablog.com/entry/20120523/1337760714">正規表現・自然言語処理</a></p></li>
<li><p><a class="reference external" href="https://spacy.io/usage/spacy-101">spacy</a></p></li>
<li><p><a class="reference external" href="https://note.com/npaka/n/nc608b9392300?magazine_key=m9a7d32c95ad9">spacy翻訳</a></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># !pip install ginza</span>
<span class="c1"># !python -m spacy download en_core_web_lg</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id3">
<h2>言語アノテーション<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>spaCyは、様々な言語アノテーションを提供します。
これは「単語の種類」、「単語間の関係」などです。
例えば、「google」が動詞として使われているか、会社名などの名詞として使われているかを示します。</p>
<p>統計モデルをインストールしたら、<code class="docutils literal notranslate"><span class="pre">spacy.load()</span></code>でモデルをロードします。これの戻り値はLanguageオブジェクトであり、通常nlpという変数に格納します。<code class="docutils literal notranslate"><span class="pre">nlp()</span></code>を呼び出すと、処理された<code class="docutils literal notranslate"><span class="pre">doc</span></code>が戻ります。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ginza</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;ja_ginza&quot;</span><span class="p">)</span>  <span class="c1"># GiNZAモデルの読み込み</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s1">&#39;吾輩は猫である。&#39;</span><span class="p">)</span> <span class="c1"># nlpにテキストを渡す</span>

<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">token</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">pos_</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">dep_</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">lemma_</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">lang_</span><span class="p">,)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>吾輩 PRON nsubj 吾輩 ja
は ADP case は ja
猫 NOUN ROOT 猫 ja
で AUX cop だ ja
ある AUX aux ある ja
。 PUNCT punct 。 ja
</pre></div>
</div>
</div>
</div>
<p>docが処理されても、元のテキストのすべての情報（空白文字など）が保持されています。
トークンのオフセットで元の文字列に取得したり、トークンとその末尾の空白文字を結合して元の文字列を再構築したりすることができます。</p>
<p>pos_は品詞を取得します。コードの意味は<a class="reference external" href="https://universaldependencies.org/docs/u/pos/">こちら</a>です。</p>
<p>dep_は構造依存関係を取得します。</p>
</div>
<div class="section" id="token">
<h2>Token化<a class="headerlink" href="#token" title="Permalink to this headline">¶</a></h2>
<p>spaCyは最初にテキストをトークン化します, すなわち, 単語や句読点などにセグメント化します. これは各言語に固有のルールを適用することによって行われます．例えば, 文末の句読点は分割する必要があります - 一方 “U.K. “は1トークンのままにしておく必要があります. それぞれのDocは個々のトークンで構成されており、それらを反復処理することができます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ginza</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;ja_ginza&quot;</span><span class="p">)</span>  <span class="c1"># GiNZAモデルの読み込み</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s1">&#39;吾輩は猫である。&#39;</span><span class="p">)</span> <span class="c1"># nlpにテキストを渡す</span>

<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">token</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>吾輩
は
猫
で
ある
。
</pre></div>
</div>
</div>
</div>
<p>まず、生のテキストを text.split(‘ ‘ ‘) のように、空白文字で分割します。次に、トークナイザーはテキストを左から右へと処理します。それぞれの部分文字列に対して、2つのチェックを行います。</p>
<ol class="simple">
<li><p>その部分文字列はトークン化の例外ルールに合致していますか？
例えば、”don’t “は空白を含まないが、”do “と “n’t “の2つのトークンに分割されるべきであり、”U.K. “は常に1つのトークンのままであるべきである。</p></li>
<li><p>接頭辞、接尾辞、接頭辞を分割することはできますか？
例えば、カンマ、ピリオド、ハイフン、引用符などの句読点。</p></li>
</ol>
<p>一致するものがあればルールが適用され、トークンライザはループを続け、新たに分割された部分文字列から開始します。このようにして、spaCy は略語の組み合わせや複数の句読点のような複雑で入れ子になったトークンを分割することができます。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>トークン化例外：文字列を複数のトークンに分割したり、句読点規則を適用したときにトークンが分割されないようにするための特殊文字列規則。
プレフィックス：文字列の先頭にある文字。
接頭：末尾の文字、例えば km, ), &quot;, !
インフィックス：間にある文字、例：-, --, /, ....
</pre></div>
</div>
<p>https://spacy.io/tokenization-57e618bd79d933c4ccd308b5739062d6.svg</p>
</div>
<div class="section" id="id4">
<h2>品詞タグと依存関係<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h2>
<p>トークン化の後, spaCyは与えられたDocを解析してタグ付けすることができます. これは、統計モデルが出てくる場所です, これは、spaCyがこのコンテキストで最も適用される可能性が高いタグまたはラベルの予測を行うことができます. モデルは、バイナリデータで構成され、それが言語全体で一般化する予測を行うためにシステムに十分な例を示すことによって生成されます - 例えば, 英語で “the “に続く単語は、最も可能性の高い名詞です.</p>
<p>言語アノテーションはToken属性として利用可能です。多くのNLPライブラリと同様に、 spaCyはすべての文字列をハッシュ値にエンコードし、メモリ使用量を減らして効率を向上させます。そのため、属性の読める文字列表現を取得するには、その名前にアンダースコア_を追加する必要があります。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ginza</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;ja_ginza&quot;</span><span class="p">)</span>  <span class="c1"># GiNZAモデルの読み込み</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s1">&#39;タカシくんはスーパーへ牛乳を買いに行きました。&#39;</span><span class="p">)</span> <span class="c1"># nlpにテキストを渡す</span>

<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">token</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">lemma_</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">pos_</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">tag_</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">dep_</span><span class="p">,</span> 
            <span class="n">token</span><span class="o">.</span><span class="n">shape_</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">is_alpha</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">is_stop</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>タカシ タカシ PROPN 名詞-固有名詞-人名-名 compound xxx True False
くん くん NOUN 接尾辞-名詞的-一般 nsubj xx True True
は は ADP 助詞-係助詞 case x True True
スーパー スーパー NOUN 名詞-普通名詞-一般 obl xxxx True False
へ へ ADP 助詞-格助詞 case x True True
牛乳 牛乳 NOUN 名詞-普通名詞-一般 obj xx True False
を を ADP 助詞-格助詞 case x True True
買い 買う VERB 動詞-一般 advcl xx True False
に に ADP 助詞-格助詞 case x True True
行き 行く VERB 動詞-非自立可能 ROOT xx True False
まし ます AUX 助動詞 aux xx True False
た た AUX 助動詞 aux x True True
。 。 PUNCT 補助記号-句点 punct 。 False False
</pre></div>
</div>
</div>
</div>
<p>各々のオフセットの内容は下記の通りである。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>テキスト：単語の原文。
ルンマ：単語の基底形。
POS（品詞）：単純なUPOS品詞タグ。
タグ：詳細品詞タグ
Dep:：構文依存性、つまりトークン間の関係
Shape（形）： 単語の形。単語の形 - 大文字化、句読点、桁。
はアルファです：トークンがアルファ文字であるかどうか。
is stop:：トークンはストップリストの一部か、つまりその言語の最も一般的な単語か。
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>
<span class="kn">from</span> <span class="nn">spacy</span> <span class="kn">import</span> <span class="n">displacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;ja_ginza&#39;</span><span class="p">)</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s1">&#39;吾輩は猫である。&#39;</span><span class="p">)</span>

<span class="c1"># https://qiita.com/youwht/items/b047225a6fc356fd56ee</span>
<span class="c1">###係り受け表示</span>
<span class="c1">#係り受けのグラフ形式を図示する</span>
<span class="c1">#Colaboratory上で直接表示するためには少々工夫を要する</span>
<span class="c1">#https://stackoverflow.com/questions/58892382/displacy-from-spacy-in-google-colab</span>
<span class="n">displacy</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s1">&#39;dep&#39;</span><span class="p">,</span> <span class="n">jupyter</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;distance&#39;</span><span class="p">:</span> <span class="mi">90</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><span class="tex2jax_ignore"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:lang="ja" id="1c71f3b9c4124c5a85611d3ce351cbca-0" class="displacy" width="500" height="227.0" direction="ltr" style="max-width: none; height: 227.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr">
<text class="displacy-token" fill="currentColor" text-anchor="middle" y="137.0">
    <tspan class="displacy-word" fill="currentColor" x="50">吾輩</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="50">PRON</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="137.0">
    <tspan class="displacy-word" fill="currentColor" x="140">は</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="140">ADP</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="137.0">
    <tspan class="displacy-word" fill="currentColor" x="230">猫</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="230">NOUN</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="137.0">
    <tspan class="displacy-word" fill="currentColor" x="320">で</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="320">AUX</tspan>
</text>

<text class="displacy-token" fill="currentColor" text-anchor="middle" y="137.0">
    <tspan class="displacy-word" fill="currentColor" x="410">ある。</tspan>
    <tspan class="displacy-tag" dy="2em" fill="currentColor" x="410">AUX</tspan>
</text>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-1c71f3b9c4124c5a85611d3ce351cbca-0-0" stroke-width="2px" d="M70,92.0 C70,2.0 230.0,2.0 230.0,92.0" fill="none" stroke="currentColor"/>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textPath xlink:href="#arrow-1c71f3b9c4124c5a85611d3ce351cbca-0-0" class="displacy-label" startOffset="50%" side="left" fill="currentColor" text-anchor="middle">nsubj</textPath>
    </text>
    <path class="displacy-arrowhead" d="M70,94.0 L62,82.0 78,82.0" fill="currentColor"/>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-1c71f3b9c4124c5a85611d3ce351cbca-0-1" stroke-width="2px" d="M70,92.0 C70,47.0 135.0,47.0 135.0,92.0" fill="none" stroke="currentColor"/>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textPath xlink:href="#arrow-1c71f3b9c4124c5a85611d3ce351cbca-0-1" class="displacy-label" startOffset="50%" side="left" fill="currentColor" text-anchor="middle">case</textPath>
    </text>
    <path class="displacy-arrowhead" d="M135.0,94.0 L143.0,82.0 127.0,82.0" fill="currentColor"/>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-1c71f3b9c4124c5a85611d3ce351cbca-0-2" stroke-width="2px" d="M250,92.0 C250,47.0 315.0,47.0 315.0,92.0" fill="none" stroke="currentColor"/>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textPath xlink:href="#arrow-1c71f3b9c4124c5a85611d3ce351cbca-0-2" class="displacy-label" startOffset="50%" side="left" fill="currentColor" text-anchor="middle">cop</textPath>
    </text>
    <path class="displacy-arrowhead" d="M315.0,94.0 L323.0,82.0 307.0,82.0" fill="currentColor"/>
</g>

<g class="displacy-arrow">
    <path class="displacy-arc" id="arrow-1c71f3b9c4124c5a85611d3ce351cbca-0-3" stroke-width="2px" d="M250,92.0 C250,2.0 410.0,2.0 410.0,92.0" fill="none" stroke="currentColor"/>
    <text dy="1.25em" style="font-size: 0.8em; letter-spacing: 1px">
        <textPath xlink:href="#arrow-1c71f3b9c4124c5a85611d3ce351cbca-0-3" class="displacy-label" startOffset="50%" side="left" fill="currentColor" text-anchor="middle">aux</textPath>
    </text>
    <path class="displacy-arrowhead" d="M410.0,94.0 L418.0,82.0 402.0,82.0" fill="currentColor"/>
</g>
</svg></span></div></div>
</div>
</div>
<div class="section" id="id5">
<h2>固有表現<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h2>
<p>固有表現とは名前が割り当てられた実世界のオブジェクトです。例えば、人、国、製品、書籍、映画などがこれにあたります。
モデルは学習データに強く依存するため、ユースケースごとに調整が必要です。</p>
<p>固有表現はdocのentで取得可能です。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ginza</span> <span class="kn">import</span> <span class="o">*</span> 
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;ja_ginza&#39;</span><span class="p">)</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s1">&#39;吾輩は猫である。&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">ent</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">start_char</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">end_char</span><span class="p">,</span> <span class="n">ent</span><span class="o">.</span><span class="n">label_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>猫 3 4 Mammal
</pre></div>
</div>
</div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Text</span><span class="p">:</span> <span class="n">The</span> <span class="n">original</span> <span class="n">entity</span> <span class="n">text</span><span class="o">.</span>
<span class="n">Start</span><span class="p">:</span> <span class="n">Index</span> <span class="n">of</span> <span class="n">start</span> <span class="n">of</span> <span class="n">entity</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">Doc</span><span class="o">.</span>
<span class="n">End</span><span class="p">:</span> <span class="n">Index</span> <span class="n">of</span> <span class="n">end</span> <span class="n">of</span> <span class="n">entity</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">Doc</span><span class="o">.</span>
<span class="n">Label</span><span class="p">:</span> <span class="n">Entity</span> <span class="n">label</span><span class="p">,</span> <span class="n">i</span><span class="o">.</span><span class="n">e</span><span class="o">.</span> <span class="nb">type</span><span class="o">.</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>
<span class="kn">from</span> <span class="nn">spacy</span> <span class="kn">import</span> <span class="n">displacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;ja_ginza&#39;</span><span class="p">)</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s1">&#39;吾輩は猫である。&#39;</span><span class="p">)</span>


<span class="n">displacy</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="n">doc</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="s1">&#39;ent&#39;</span><span class="p">,</span> <span class="n">jupyter</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;distance&#39;</span><span class="p">:</span> <span class="mi">90</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><span class="tex2jax_ignore"><div class="entities" style="line-height: 2.5; direction: ltr">吾輩は
<mark class="entity" style="background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;">
    猫
    <span style="font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem">Mammal</span>
</mark>
である。</div></span></div></div>
</div>
</div>
<div class="section" id="id6">
<h2>単語ベクトルと類似度<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h2>
<p>単語の類似度は、単語ベクトル（word vector）を比較することによって計算します。
単語ベクトルはword2vecを使用して生成でき、次のような形式で表されます。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># BANANA.VECTOR</span>
<span class="n">array</span><span class="p">([</span><span class="mf">2.02280000e-01</span><span class="p">,</span>  <span class="o">-</span><span class="mf">7.66180009e-02</span><span class="p">,</span>   <span class="mf">3.70319992e-01</span><span class="p">,</span>
     <span class="mf">3.28450017e-02</span><span class="p">,</span>  <span class="o">-</span><span class="mf">4.19569999e-01</span><span class="p">,</span>   <span class="mf">7.20689967e-02</span><span class="p">,</span>
    <span class="o">-</span><span class="mf">3.74760002e-01</span><span class="p">,</span>   <span class="mf">5.74599989e-02</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.24009997e-02</span><span class="p">,</span>
     <span class="mf">5.29489994e-01</span><span class="p">,</span>  <span class="o">-</span><span class="mf">5.23800015e-01</span><span class="p">,</span>  <span class="o">-</span><span class="mf">1.97710007e-01</span><span class="p">,</span>
    <span class="o">-</span><span class="mf">3.41470003e-01</span><span class="p">,</span>   <span class="mf">5.33169985e-01</span><span class="p">,</span>  <span class="o">-</span><span class="mf">2.53309999e-02</span><span class="p">,</span>
     <span class="mf">1.73800007e-01</span><span class="p">,</span>   <span class="mf">1.67720005e-01</span><span class="p">,</span>   <span class="mf">8.39839995e-01</span><span class="p">,</span>
     <span class="mf">5.51070012e-02</span><span class="p">,</span>   <span class="mf">1.05470002e-01</span><span class="p">,</span>   <span class="mf">3.78719985e-01</span><span class="p">,</span>
     <span class="mf">2.42750004e-01</span><span class="p">,</span>   <span class="mf">1.47449998e-02</span><span class="p">,</span>   <span class="mf">5.59509993e-01</span><span class="p">,</span>
     <span class="mf">1.25210002e-01</span><span class="p">,</span>  <span class="o">-</span><span class="mf">6.75960004e-01</span><span class="p">,</span>   <span class="mf">3.58420014e-01</span><span class="p">,</span>
     <span class="c1"># ... and so on ...</span>
     <span class="mf">3.66849989e-01</span><span class="p">,</span>   <span class="mf">2.52470002e-03</span><span class="p">,</span>  <span class="o">-</span><span class="mf">6.40089989e-01</span><span class="p">,</span>
    <span class="o">-</span><span class="mf">2.97650009e-01</span><span class="p">,</span>   <span class="mf">7.89430022e-01</span><span class="p">,</span>   <span class="mf">3.31680000e-01</span><span class="p">,</span>
    <span class="o">-</span><span class="mf">1.19659996e+00</span><span class="p">,</span>  <span class="o">-</span><span class="mf">4.71559986e-02</span><span class="p">,</span>   <span class="mf">5.31750023e-01</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>注意</strong>
spacyにはいくつかモデルがあり、通常smで終わるものは小さなモデルを表します。そして、これには単語ベクトルが付属せず、similarity()を使用して各種属性を比較することはできますが、精度はそれほどよくありません。そのため、実際に単語ベクトルを使用する際にはlgで終わるものなどより大きなモデルを使用してください。</p>
<p>単語ベクトルが組み込まれたモデルではToken.vectorとして使用できます。Doc.vectorとSpan.vectorはデフォルトでトークンベクトルの平均になります。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;ja_ginza&#39;</span><span class="p">)</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s1">&#39;犬　猫　亀　アップル　オレンジ&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">token</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">has_vector</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">vector_norm</span><span class="p">,</span> <span class="n">token</span><span class="o">.</span><span class="n">is_oov</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>犬 True 3.4318957 False
　 False 0.0 True
猫 True 3.1371322 False
　 False 0.0 True
亀 True 3.648572 False
　 False 0.0 True
アップル True 3.9742024 False
　 False 0.0 True
オレンジ True 3.5486767 False
</pre></div>
</div>
</div>
</div>
<p>上記の単語は動物と果物を表し、一般的な語彙の一部であるためベクトルがついているが、一般的な語彙に含まれないものにはベクトルがついていないことがあります。これをカバーするためにはより大きいモデルをロードすることを検討してください。</p>
<p>spacyは2つのオブジェクトを比較し、それらがどの程度類似しているかを予測できます。</p>
<p>Doc、Span、Tokenにはsimilarity()が付属しており、これを使用して他のオブジェクトと比較し、類似度を判断できます。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;ja_ginza&#39;</span><span class="p">)</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s1">&#39;犬　猫　アップル&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">token1</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">token2</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">token1</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">token2</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">token1</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="n">token2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>犬 犬 1.0
犬 　 0.0
犬 猫 0.727109
犬 　 0.0
犬 アップル 0.09544731
　 犬 0.0
　 　 1.0
　 猫 0.0
　 　 1.0
　 アップル 0.0
猫 犬 0.727109
猫 　 0.0
猫 猫 1.0
猫 　 0.0
猫 アップル 0.08162258
　 犬 0.0
　 　 1.0
　 猫 0.0
　 　 1.0
　 アップル 0.0
アップル 犬 0.09544731
アップル 　 0.0
アップル 猫 0.08162258
アップル 　 0.0
アップル アップル 1.0
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/apple/Documents/github/MyJupyterBookShelf/.venv/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.
  
</pre></div>
</div>
</div>
</div>
<p>この場合、モデルの予測はほぼ適切です。同一のトークンは明らかに100%互いに類似しています。ただし、ベクトル演算と浮動小数点の計算のために必ずしも1.0とは限りません。</p>
</div>
<div class="section" id="id7">
<h2>パイプライン<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<p>テキストに対してnlpを呼び出すと、spacyはテキストをトークン化してDocオブジェクトを生成します。その後、ドキュメントはいくつかのステップで処理されます。これを「処理パイプライン」とも呼ばれます。デフォルトモデルで使用されるパイプラインはタガー、パーサー、エンティティリコグナイざーを含みます。各要素は処理されたDocを返します。</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>名称</p></th>
<th class="head"><p>コンポーネント</p></th>
<th class="head"><p>生成物</p></th>
<th class="head"><p>説明</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>tokenizer</p></td>
<td><p>Tokenizer</p></td>
<td><p>Doc</p></td>
<td><p>テキストをトークンに分割</p></td>
</tr>
<tr class="row-odd"><td><p>tagger</p></td>
<td><p>Tagger</p></td>
<td><p>Doc[i].tag</p></td>
<td><p>品詞タグ付け</p></td>
</tr>
<tr class="row-even"><td><p>parser</p></td>
<td><p>DependencyParser</p></td>
<td><p>Doc[i].head, Doc[i].dep, Doc.sents, Doc.noun_chunks</p></td>
<td><p>依存関係ラベルを割り当て</p></td>
</tr>
<tr class="row-odd"><td><p>ner</p></td>
<td><p>EntityRecognizer</p></td>
<td><p>Doc.ents, Doc[i].ent_iob, Doc[i].ent_type</p></td>
<td><p>固有表現を検出してラベル付け</p></td>
</tr>
<tr class="row-even"><td><p>textcat</p></td>
<td><p>TextCategorizer</p></td>
<td><p>Doc.cats</p></td>
<td><p>ドキュメントラベルを割り当て</p></td>
</tr>
<tr class="row-odd"><td><p>….</p></td>
<td><p>custom components</p></td>
<td><p>Doc.<em>.xxx, Token.</em>.xxx, Span._.xxx</p></td>
<td><p>カスタム属性、メソッド、プロパティを割り当て</p></td>
</tr>
</tbody>
</table>
<p>処理パイプラインは、常に統計モデルとその能力に依存する。例えば、モデルがエンティティラベルの予測を行うためのデータを含む場合にのみ、パイプラインはエンティティ認識コンポーネントを含むことができます。このため、各モデルは、コンポーネント名を含む単純なリストとして、そのメタデータで使用するパイプラインを指定します。</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="s2">&quot;pipeline&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;tagger&quot;</span><span class="p">,</span> <span class="s2">&quot;parser&quot;</span><span class="p">,</span> <span class="s2">&quot;ner&quot;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="vocab-hashe-lexeme">
<h2>語彙(Vocab)、ハッシュ(hashe)、見出し(lexeme)<a class="headerlink" href="#vocab-hashe-lexeme" title="Permalink to this headline">¶</a></h2>
<p>可能な限り, spaCyは複数のドキュメントで共有されるボキャブラリー, Vocabにデータを格納しようとします. メモリを節約するために, spaCyはまた、すべての文字列をハッシュ値にエンコードします - この例では, “coffee “はハッシュ3197928453018144401を持っています. ORG “のようなエンティティラベルや “VERB “のような品詞タグもエンコードされます. 内部的には、spaCyはハッシュ値の中で「話す」だけです。</p>
<p>https://spacy.io/vocab_stringstore-1d1c9ccd7a1cf4d168bfe4ca791e6eed.svg</p>
<p>あなたは、すべての異なるコンテキストの種類の単語 “コーヒー “を含むドキュメントの多くを処理する場合, 毎回正確な文字列 “コーヒー “を格納するには、あまりにも多くのスペースを取るだろう. そこで代わりに、 spaCy は文字列をハッシュして StringStore に保存します。あなたは、両方の方向で動作するルックアップテーブルとしてStringStoreを考えることができます - あなたは、そのハッシュを取得するために文字列を調べることができます, またはその文字列を取得するためにハッシュ.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ginza</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;ja_ginza&quot;</span><span class="p">)</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s2">&quot;私はコーヒーが好きです&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">strings</span><span class="p">[</span><span class="s2">&quot;コーヒー&quot;</span><span class="p">])</span>  <span class="c1"># 3197928453018144401</span>
<span class="nb">print</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">strings</span><span class="p">[</span><span class="mi">16003280304011083252</span><span class="p">])</span>  <span class="c1"># &#39;コーヒー&#39;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>16003280304011083252
コーヒー
</pre></div>
</div>
</div>
</div>
<p>すべての文字列がエンコードされているので、語彙のエントリは単語テキストを含む必要はありません。その代わりに、ハッシュ値を使ってStringStoreで検索することができます。語彙の各エントリはLexemeとも呼ばれ、単語に関する文脈に依存しない情報を含んでいます。例えば、”love “がある文脈で動詞や名詞として使われていても、その綴りやアルファベットで構成されているかどうかは変わりません。また、そのハッシュ値も常に同じです。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ginza</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;ja_ginza&quot;</span><span class="p">)</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s2">&quot;私はコーヒーが好きです&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">doc</span><span class="p">:</span>
    <span class="n">lexeme</span> <span class="o">=</span> <span class="n">doc</span><span class="o">.</span><span class="n">vocab</span><span class="p">[</span><span class="n">word</span><span class="o">.</span><span class="n">text</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">lexeme</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">lexeme</span><span class="o">.</span><span class="n">orth</span><span class="p">,</span> <span class="n">lexeme</span><span class="o">.</span><span class="n">shape_</span><span class="p">,</span> <span class="n">lexeme</span><span class="o">.</span><span class="n">prefix_</span><span class="p">,</span> <span class="n">lexeme</span><span class="o">.</span><span class="n">suffix_</span><span class="p">,</span>
            <span class="n">lexeme</span><span class="o">.</span><span class="n">is_alpha</span><span class="p">,</span> <span class="n">lexeme</span><span class="o">.</span><span class="n">is_digit</span><span class="p">,</span> <span class="n">lexeme</span><span class="o">.</span><span class="n">is_title</span><span class="p">,</span> <span class="n">lexeme</span><span class="o">.</span><span class="n">lang_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>私 8621763682285386465 x 私 私 True False False ja
は 16159406377086191121 x は は True False False ja
コーヒー 16003280304011083252 xxxx コ ーヒー True False False ja
が 7715757715875749221 x が が True False False ja
好き 8461799995404172894 xx 好 好き True False False ja
です 4844028926029883277 xx で です True False False ja
</pre></div>
</div>
</div>
</div>
<p>単語のハッシュへのマッピングは、どのような状態にも依存しません。各値が一意であることを確認するために, spaCyは、単語の文字列に基づいてハッシュを計算するためにハッシュ関数を使用しています. これはまた、 “コーヒー “のハッシュは常に同じになることを意味します, あなたが使用しているモデルやどのようにあなたがspaCyを設定したかに関係なく.</p>
<p>しかし, ハッシュを逆にすることはできませんし、3197928453018144401を解決する方法はありません。spaCyができるのは語彙で調べることだけです。だからこそ、あなたが作成するすべてのオブジェクトが同じ語彙にアクセスできることを常に確認する必要があります。彼らがそうでない場合、spaCyはそれが必要とする文字列を見つけることができないかもしれません。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>
<span class="kn">from</span> <span class="nn">spacy.tokens</span> <span class="kn">import</span> <span class="n">Doc</span>
<span class="kn">from</span> <span class="nn">spacy.vocab</span> <span class="kn">import</span> <span class="n">Vocab</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;ja_ginza&#39;</span><span class="p">)</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="s2">&quot;私はコーヒーが好きです&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">strings</span><span class="p">[</span><span class="s1">&#39;コーヒー&#39;</span><span class="p">])</span>  <span class="c1"># 16003280304011083252</span>
<span class="nb">print</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">strings</span><span class="p">[</span><span class="mi">16003280304011083252</span><span class="p">])</span>  <span class="c1"># &#39;コーヒー&#39;</span>

<span class="n">empty_doc</span> <span class="o">=</span> <span class="n">Doc</span><span class="p">(</span><span class="n">Vocab</span><span class="p">())</span>  <span class="c1"># 空のVocabを含む新しいドキュメントを生成</span>
<span class="c1"># empty_doc.vocab.strings[16003280304011083252] エラー発生</span>

<span class="n">empty_doc</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">strings</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="s2">&quot;コーヒー&quot;</span><span class="p">)</span>  <span class="c1"># 「コーヒー」を追加してハッシュを生成</span>
<span class="nb">print</span><span class="p">(</span><span class="n">empty_doc</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">strings</span><span class="p">[</span><span class="mi">16003280304011083252</span><span class="p">])</span>  <span class="c1"># &#39;コーヒー&#39; 👍</span>

<span class="n">new_doc</span> <span class="o">=</span> <span class="n">Doc</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">vocab</span><span class="p">)</span>  <span class="c1"># 最初のドキュメントの語彙で新しいドキュメントを生成</span>
<span class="nb">print</span><span class="p">(</span><span class="n">new_doc</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">strings</span><span class="p">[</span><span class="mi">16003280304011083252</span><span class="p">])</span>  <span class="c1"># &#39;コーヒー&#39; 👍</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>16003280304011083252
コーヒー
コーヒー
コーヒー
</pre></div>
</div>
</div>
</div>
<p>語彙に3197928453018144401の文字列が含まれていない場合、spaCyはエラーを発生させます。あなたは手動で “coffee “を再追加することができますが、これはあなたが実際にドキュメントにその単語が含まれていることを知っている場合にのみ動作します。この問題を防ぐために, spaCy はまた、Doc または nlp オブジェクトを保存するときに Vocab をエクスポートします. これはあなたにオブジェクトとそのエンコードされた注釈を与えます, 加えてそれをデコードするための “キー”.が提供されます。</p>
</div>
<div class="section" id="id8">
<h2>ナレッジベース<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p>「spaCy」はエンティティリンクタスクをサポートするために、外部ナレッジをナレッジベースに保存します。「ナレッジベース」（KB）はVocabを使用してデータを効率的に保存します。</p>
<p>「ナレッジベース」は、最初にすべてのエンティティを追加することによって作成されます。次に、潜在的な言及またはエイリアスごとに、関連するKB IDとそれらの以前の確率のリストが追加されます。これらの事前確率の合計は、特定のエイリアスで1を超えてはなりません。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>
<span class="kn">from</span> <span class="nn">spacy.kb</span> <span class="kn">import</span> <span class="n">KnowledgeBase</span>

<span class="c1"># モデルを読み込み、空のナレッジベースを作成</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;ja_ginza&#39;</span><span class="p">)</span>
<span class="n">kb</span> <span class="o">=</span> <span class="n">KnowledgeBase</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">nlp</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">entity_vector_length</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># エンティティの追加</span>
<span class="n">kb</span><span class="o">.</span><span class="n">add_entity</span><span class="p">(</span><span class="n">entity</span><span class="o">=</span><span class="s2">&quot;Q1004791&quot;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">entity_vector</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">kb</span><span class="o">.</span><span class="n">add_entity</span><span class="p">(</span><span class="n">entity</span><span class="o">=</span><span class="s2">&quot;Q42&quot;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="mi">342</span><span class="p">,</span> <span class="n">entity_vector</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">])</span>
<span class="n">kb</span><span class="o">.</span><span class="n">add_entity</span><span class="p">(</span><span class="n">entity</span><span class="o">=</span><span class="s2">&quot;Q5301561&quot;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">entity_vector</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="c1"># エイリアスの追加</span>
<span class="n">kb</span><span class="o">.</span><span class="n">add_alias</span><span class="p">(</span><span class="n">alias</span><span class="o">=</span><span class="s2">&quot;Douglas&quot;</span><span class="p">,</span> <span class="n">entities</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Q1004791&quot;</span><span class="p">,</span> <span class="s2">&quot;Q42&quot;</span><span class="p">,</span> <span class="s2">&quot;Q5301561&quot;</span><span class="p">],</span> <span class="n">probabilities</span><span class="o">=</span><span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>
<span class="n">kb</span><span class="o">.</span><span class="n">add_alias</span><span class="p">(</span><span class="n">alias</span><span class="o">=</span><span class="s2">&quot;Douglas Adams&quot;</span><span class="p">,</span> <span class="n">entities</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Q42&quot;</span><span class="p">],</span> <span class="n">probabilities</span><span class="o">=</span><span class="p">[</span><span class="mf">0.9</span><span class="p">])</span>

<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of entities in KB:&quot;</span><span class="p">,</span><span class="n">kb</span><span class="o">.</span><span class="n">get_size_entities</span><span class="p">())</span> <span class="c1"># 3</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of aliases in KB:&quot;</span><span class="p">,</span> <span class="n">kb</span><span class="o">.</span><span class="n">get_size_aliases</span><span class="p">())</span> <span class="c1"># 2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of entities in KB: 3
Number of aliases in KB: 2
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id9">
<h2>候補生成<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h2>
<p>テキストエンティティが与えられた場合、ナレッジベースは、もっともらしい候補またはエンティティ識別子のリストを提供します。EntityLinkerは、候補のこのリストを入力として受け取り、ドキュメントのコンテキストを前提として、言及を最も可能性の高い識別子に変換します。</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>
<span class="kn">from</span> <span class="nn">spacy.kb</span> <span class="kn">import</span> <span class="n">KnowledgeBase</span>

<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;ja_ginza&#39;</span><span class="p">)</span>
<span class="n">kb</span> <span class="o">=</span> <span class="n">KnowledgeBase</span><span class="p">(</span><span class="n">vocab</span><span class="o">=</span><span class="n">nlp</span><span class="o">.</span><span class="n">vocab</span><span class="p">,</span> <span class="n">entity_vector_length</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># エンティティの追加</span>
<span class="n">kb</span><span class="o">.</span><span class="n">add_entity</span><span class="p">(</span><span class="n">entity</span><span class="o">=</span><span class="s2">&quot;Q1004791&quot;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">entity_vector</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">kb</span><span class="o">.</span><span class="n">add_entity</span><span class="p">(</span><span class="n">entity</span><span class="o">=</span><span class="s2">&quot;Q42&quot;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="mi">342</span><span class="p">,</span> <span class="n">entity_vector</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">])</span>
<span class="n">kb</span><span class="o">.</span><span class="n">add_entity</span><span class="p">(</span><span class="n">entity</span><span class="o">=</span><span class="s2">&quot;Q5301561&quot;</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">entity_vector</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>

<span class="c1"># エイリアスの追加</span>
<span class="n">kb</span><span class="o">.</span><span class="n">add_alias</span><span class="p">(</span><span class="n">alias</span><span class="o">=</span><span class="s2">&quot;Douglas&quot;</span><span class="p">,</span> <span class="n">entities</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Q1004791&quot;</span><span class="p">,</span> <span class="s2">&quot;Q42&quot;</span><span class="p">,</span> <span class="s2">&quot;Q5301561&quot;</span><span class="p">],</span> <span class="n">probabilities</span><span class="o">=</span><span class="p">[</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">])</span>

<span class="n">candidates</span> <span class="o">=</span> <span class="n">kb</span><span class="o">.</span><span class="n">get_candidates</span><span class="p">(</span><span class="s2">&quot;Douglas&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">candidates</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">.</span><span class="n">entity_</span><span class="p">,</span> <span class="n">c</span><span class="o">.</span><span class="n">prior_prob</span><span class="p">,</span> <span class="n">c</span><span class="o">.</span><span class="n">entity_vector</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  Q1004791 0.6000000238418579 [0.0, 3.0, 5.0]
  Q42 0.10000000149011612 [1.0, 9.0, -3.0]
  Q5301561 0.20000000298023224 [-2.0, 4.0, 2.0]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id10">
<h2>シリアライズ<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h2>
<p>パイプライン、語彙、ベクトル、エンティティを変更したり、モデルを更新したりしている場合は、最終的には進捗状況を保存する必要があります（たとえば、nlpオブジェクトにあるものすべて）。つまり、その内容と構造を、ファイルやバイト文字列などの保存可能な形式に変換する必要があります。このプロセスはシリアル化と呼ばれます。 「spaCy」には、シリアル化メソッドが組み込まれており、Pickleプロトコルをサポートしています。</p>
<p>すべてのコンテナクラス、つまり言語（nlp）、Doc、Vocab、StringStoreには、次のメソッドが用意されています。</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>メソッド</p></th>
<th class="head"><p>戻り値</p></th>
<th class="head"><p>例</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>to_bytes</p></td>
<td><p>bytes</p></td>
<td><p>data=nlp.to_bytes()</p></td>
</tr>
<tr class="row-odd"><td><p>from_bytes</p></td>
<td><p>object</p></td>
<td><p>nlp.from_bytes(data)</p></td>
</tr>
<tr class="row-even"><td><p>to_disk</p></td>
<td><p>-</p></td>
<td><p>nlp.to_disk(“/path”)</p></td>
</tr>
<tr class="row-odd"><td><p>from_disk</p></td>
<td><p>object</p></td>
<td><p>nlp.from_disk(“/path”)</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id11">
<h2>訓練<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h2>
<p>spaCyのモデルは統計的であり、彼らが行うすべての “決定” - 例えば, どの品詞タグを割り当てるための品詞タグ, または単語が名前付きエンティティであるかどうか - 予測です. この予測は、モデルが訓練中に見てきた例に基づいています. モデルを訓練するには、まず訓練データ、つまりテキストの例と、モデルに予測させたいラベルが必要です。これは、品詞タグ、名前付きエンティティ、またはその他の情報である可能性があります。</p>
<p>次に、モデルはラベルの付いていないテキストを表示し、予測を行います。正解がわかっているので、学習例と期待される出力との差を計算する損失関数の誤差勾配の形で、予測に対するフィードバックをモデルに与えることができます。差が大きければ大きいほど、勾配はより重要になり、モデルの更新はより重要になります。</p>
<p>https://spacy.io/training-73950e71e6b59678754a87d6cf1481f9.svg</p>
<p>モデルを訓練するとき、我々はモデルに単に例を記憶させるだけではなく、他の例で一般化できる理論を考え出させたいのです。結局のところ、ここにある “Amazon “のインスタンスが会社であることをモデルに学習させるだけではなく、このような文脈で “Amazon “が会社である可能性が高いことをモデルに学習させたいのです。そのため、学習データは常に我々が処理したいデータを代表するものでなければなりません。一人称の文章が非常に稀であるWikipediaで訓練されたモデルは、おそらくTwitterでは悪い結果になるでしょう。同様に、恋愛小説で訓練されたモデルは、法的な文章では悪い結果になる可能性が高いです。</p>
<p>これは、モデルがどのように動作しているか、正しい学習をしているかどうかを知るためには、トレーニングデータだけではなく、評価データも必要であることを意味します。もしモデルが訓練されたデータだけでテストした場合、モデルがどれだけ一般化しているかはわかりません。ゼロからモデルを訓練したい場合、通常、訓練と評価の両方に少なくとも数百の例が必要です。既存のモデルを更新するには、非常に少ない例ですでにまともな結果を得ることができます。</p>
</div>
<div class="section" id="id12">
<h2>言語データ<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h2>
<p>すべての言語は異なります - そして通常、特に最も一般的な単語の中には、例外や特殊なケースがたくさんあります。これらの例外の中には言語間で共有されているものもあれば、完全に特殊なものもあります - 通常はハードコーディングが必要なほど特殊です。langモジュールには、すべての言語固有のデータが含まれており、シンプルなPythonファイルにまとめられています。これにより、データの更新や拡張が容易になります。</p>
<p>例えば、基本的な句読点、絵文字、エモジ、エモーティコン、一文字の略語、「」や「」のようなスペルの異なる等価トークンのための規範などです。これにより、モデルはより正確な予測を行うことができます。サブモジュールの個々の言語データには、特定の言語にのみ関連するルールが含まれています。また、すべてのコンポーネントをまとめたり、言語サブクラスを作成したりします。</p>
<p>https://spacy.io/language_data-ef63e6a58b7ec47c073fb59857a76e5f.svg</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">spacy.lang.en</span> <span class="kn">import</span> <span class="n">English</span>
<span class="kn">from</span> <span class="nn">spacy.lang.de</span> <span class="kn">import</span> <span class="n">German</span>
<span class="kn">from</span> <span class="nn">spacy.lang.ja</span> <span class="kn">import</span> <span class="n">Japanese</span>

<span class="n">nlp_en</span> <span class="o">=</span> <span class="n">English</span><span class="p">()</span>  <span class="c1"># Includes English data</span>
<span class="n">nlp_de</span> <span class="o">=</span> <span class="n">German</span><span class="p">()</span>  <span class="c1"># Includes German data</span>
<span class="n">nlp_ja</span> <span class="o">=</span> <span class="n">Japanese</span><span class="p">()</span> <span class="c1"># includes Japanese Data</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="id13">
<h2>アーキテクチャ<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h2>
<p>spaCyの中心的なデータ構造はDocとVocabです。Docオブジェクトは，トークンのシーケンスとそのすべてのアノテーションを所有しています．Vocabオブジェクトは、ドキュメント間で共通の情報を利用可能にするルックアップテーブルのセットを所有しています。文字列、単語ベクトル、語彙属性を一元化することで、これらのデータの複数のコピーを保存する必要がなくなります。これにより、メモリを節約し、真実のソースが単一であることを保証します。</p>
<p>テキスト注釈はまた、単一の真実のソースを使用できるように設計されています：Doc オブジェクトはデータを所有し、Span と Token はそのデータを指すビューです。Doc オブジェクトは Tokenizer によって構築され、パイプラインのコンポーネントによってその場で修正されます。Language オブジェクトは、これらのコンポーネントを調整します。生のテキストを取得してパイプラインに送り、注釈付きのドキュメントを返します。また、トレーニングとシリアライゼーションのオーケストレーションも行います。</p>
<p>https://spacy.io/architecture-bcdfffe5c0b9f221a2f6607f96ca0e4a.svg</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./contents"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="IntroToGINZA.html" title="previous page">What is GINZA?</a>
    <a class='right-next' id="next-link" href="translation/trans.html" title="next page">記事翻訳</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By ironball<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
    <!-- Google Analytics -->
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-180974113-1', 'auto');
      ga('set', 'anonymizeIp', true);
      ga('send', 'pageview');
    </script>
    <script async src='https://www.google-analytics.com/analytics.js'></script>
    <!-- End Google Analytics -->
    
  </body>
</html>